#!/usr/bin/python2.7
############################################################
##    FILENAME:   process_users.py    
##    VERSION:    1.5
##    SINCE:      2014-03-24
##    AUTHOR: 
##        Jimmy Lin (xl5224) - JimmyLin@utexas.edu  
##
############################################################
##    Edited by MacVim
##    Documentation auto-generated by Snippet 
############################################################
import csv
from nltk.stem.lancaster import LancasterStemmer
from nltk.stem.isri import ISRIStemmer
from nltk.corpus import words
from vectorizeTexts import unique

WORDS = set(words.words())

def merge_major(major_dict):
    st = LancasterStemmer()
    isri = ISRIStemmer()
    major_list = []
    for major in major_dict.keys():
        # preprocessing
        major = major.replace("&", " ")
        major = major.replace(".", " ")
        major = major.replace("/", " ")
        lowcase_major = major.lower()
        separated_majors = lowcase_major.split(" ")
        for i in range(len(separated_majors)):
            if separated_majors[i] in WORDS:
                if len(separated_majors[i]) <= 3:
                    continue
                major_list.append(st.stem(separated_majors[i]))

    uniqtokens, nbefore, nafter = unique(major_list)

    final_dict = {}
    index = 1
    for major in uniqtokens:
        if final_dict.has_key(major):
            pass
        else:
            final_dict.update({major:index})
            index += 1
     
    return final_dict


with open('./../Dataset/users.tsv','rb') as tsvin, \
    open('./trainUsers.csv', 'wb') as csvTrainOut, \
    open('./testUsers.csv', 'wb') as csvTestOut:
    tsvin = csv.reader(tsvin, delimiter='\t')
    csvTrainOut = csv.writer(csvTrainOut)
    csvTestOut = csv.writer(csvTestOut)

    '''
    UserID,WindowID,Split,City,State,Country,ZipCode,DegreeType,Major,
    WorkHistoryCount,TotalYearsExperience,CurrentlyEmployed,ManagedOthers,ManagedHowMany
    '''
    header = tsvin.next()
    nColumns = len(header)

    dictionaries = [] # dictionary for discretizing each column
    values = [] # numerical count of distinct label
    for i in range(0, nColumns):
        dictionaries.append({})
        values.append(0)

    ## DISCRITIZATION
    discretSet = range(3,9) + range(12,14) # set of index to discretize
    removeSet = [2,3,5,6,9] # set of index to remove
    remainedSet = list(set(range(0,len(header))).difference(set(removeSet)))
    remainedSet.sort()
    zipIdx = 6
    SCSUsers = [] # users matrix by simple coding scheme
    BCSUsers = [] # users matrix by binary coding scheme
    newheader = [header[i] for i in remainedSet]
    csvTestOut.writerows([newheader])
    csvTrainOut.writerows([newheader])

    for user in tsvin:
        split = user[2]
        userid = user[0]
        for i in discretSet:
            key = user[i]
            #if i == zipIdx:
            #    key = key[:-1]
            if not dictionaries[i].has_key(key):
                dictionaries[i][key] = values[i]
                values[i] += 1
            user[i] = dictionaries[i][key]

        scsUser = [user[i] for i in remainedSet]
        if split == 'Test':
            csvTestOut.writerows([scsUser])
        else:
            csvTrainOut.writerows([scsUser])
        SCSUsers.append(scsUser)

    ## merge MAJOR
    MAJOR_IDX = 8
    dictionaries[MAJOR_IDX] = merge_major(dictionaries[MAJOR_IDX])
    values[MAJOR_IDX] = len(dictionaries[MAJOR_IDX].keys())

    nSCSFeatures = len(SCSUsers[0])
    print "nSCSFeatures:", nSCSFeatures
    
    print "Domain size of each variables: "
    newheader = []
    for i in range(0, nColumns):
        if i in removeSet: continue
        if values[i] <= 0: values[i] = 1
        print "  ", header[i], values[i]
        newheader = newheader + [header[i]] * values[i]

    ## output the accumulated counter
    for i in range(nColumns):
        if i in removeSet: continue
        domainSize = len(dictionaries[i].items())
        if not (domainSize == 0):
            print '===========', header[i], '==========='
            items = dictionaries[i].items()
            if domainSize <= 300 or True:
                for key, value in items:
                    print key, ":::",  value
            else:
                print items[1][0], ":::",  items[1][1]
                print "::::::::::::::::::::::::::::::"
                print items[-1][0], ":::",  items[-1][1]
    ## HEADER FORMULATION
    '''
    csvTrainOut.writerows([newheader])
    csvTestOut.writerows([newheader])
    nBCSFeatures = None
    for scsUser in SCSUsers:
        bcsUser = [] # new user vector in binary coding scheme
        for i in range(0, nSCSFeatures):
            if i in removeSet: # ignore feature to be removed
                continue
            if i in discretSet: # 
                temp = [0 for x in range(0,values[i])]
                temp[scsUser[i]] = 1
                bcsUser = bcsUser + temp
            else: #
                bcsUser.append(scsUser[i])
        ## display the binary encoding result and guarantee its safety
        if nBCSFeatures is None:
            nBCSFeatures = len(bcsUser)
            print "nBCSFeatures (total):", nBCSFeatures
        else:
            assert(nBCSFeatures == len(bcsUser))
        #BCSUsers.append(bcsUser)
        ## output to external csv, piece by piece
        if split == 'Test':
            csvTestOut.writerows([bcsUser])
        else:
            csvTrainOut.writerows([bcsUser])
    '''
