############################################################
##    FILENAME:   process_jobs.py    
##    VERSION:    1.2
##    SINCE:      2014-03-24
##    AUTHOR: 
##        Jimmy Lin (xl5224) - JimmyLin@utexas.edu  
##
############################################################
##    Edited by MacVim
##    Documentation auto-generated by Snippet 
############################################################

import csv
import re
from vectorizeTexts import *

#TODO: use more elegant natural language method to extract useful words

with open('./sampleData/sampled_jobs.tsv','rb') as tsvin,\
        open('./sampleData/newJobs.csv', 'wb') as csvout, \
        open('./keywords.conf', 'rb') as keywordConf:
    tsvin = csv.reader(tsvin, delimiter='\t')
    csvout = csv.writer(csvout)

    # process header
    header = tsvin.next()
    nColumns = len(header)

    # preparation for non-textual discretization
    dictionaries = [] # dictionary for discretizing each column
    values = [] # numerical count of distinct label
    for i in range(0, nColumns):
        dictionaries.append({})
        values.append(0)

    # preparation for textual discretization
    keywords = []
    for line in keywordConf:
        line = line.strip("\n")
        [kw, f, df] = line.split(" ")
        keywords.append(kw)

    nKeywords = len(keywords)
    print "nKeywords:", nKeywords

    header[-1] = header[-1].strip("\n")
    csvout.writerows([[header[0]]+ [header[2]] + header[5:9] + header[11:] + \
                      ["kw:"+str(x) for x in keywords]])

    discretSet = [2] + range(5,9) # set of index
    desIndex = 3
    
    for row in tsvin:
        # non-textual feature
        for i in discretSet:
            if not dictionaries[i].has_key(row[i]):
                dictionaries[i][row[i]] = values[i]
                values[i] += 1
            row[i] = dictionaries[i][row[i]]
        # textual feature
        description = row[desIndex]
        tokens = nltk.word_tokenize(description)
        text = nltk.Text(tokens)
        text.tokens = processTokens(text.tokens)
        tfeat = []
        for i in range(0, nKeywords):
            
            count = text.count(keywords[i])
            if count >= 1:
                tfeat.append(1)
            else:
                tfeat.append(0)
        # write to out file
        jobFeature = [row[0]]+ [row[2]] + row[5:9] + tfeat
        print jobFeature
        csvout.writerows([jobFeature])
   #
