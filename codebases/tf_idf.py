############################################################
##    FILENAME:   tf_idf.py    
##    VERSION:    1.0
##    SINCE:      2014-03-01
##    AUTHOR: 
##        Jimmy Lin (xl5224) - JimmyLin@utexas.edu  
##
############################################################
##    Edited by MacVim
##    Documentation auto-generated by Snippet 
############################################################

import nltk.corpus
from nltk.corpus import stopwords
from nltk.text import TextCollection
from nltk.text import Text


def createTextFromTxtFile (fn):
    '''    
    Create text object from external text file
    Input: 
        fn - name of the text file
    Output:
        text 
    '''
    f = open (fn, 'rU')
    raw = f.read()
    tokens = nltk.word_tokenize(raw)
    text = nltk.Text(tokens)
    return text

def getTextFromString (textString, removeStopwords=True):
    '''
    Get text from the input string
    Input:
        textString - text string
        removeStopwords - specify whether to remove stop words
    Output:
        text - Text object containing the input string
    '''
    stop = stopwords.words('english')
    tokens = nltk.word_tokenize(textString)
    if removeStopwords:
        ptokens = [i for i in tokens if i not in stop]
    text = nltk.Text(ptokens)
    return text, ptokens

def getTextCollectionFromTxtFile (fn):
    '''
    Create text collection from external text files
    Input:
        fn - name of the external text file
    Output:
        textCollection containing all texts in the given file
    '''
    f = open (fn, 'rU')
    tc = []
    alltokens = []
    for line in f:
        text, tokens = getTextFromString(line)
        tc.append(text)
        alltokens.extend(tokens)
    return TextCollection(tc), alltokens

def unique (tokens):
    '''
    deduplicate the tokens
    '''
    nbefore = len(tokens)
    tokensAfterUniq = set(alltokens)
    nafter = len(tokensAfterUniq)
    return list(tokensAfterUniq), nbefore, nafter

def computeTF (term, text, alltexts):
    '''
    Compute the TF from text collection
    Input:
        term - 
        text
        alltexts - text collections
    Output:
        tf
    '''
    tf = alltexts.tf(term, text)
    return tf

if __name__ == '__main__':
    alltexts, alltokens = getTextCollectionFromTxtFile('./sampled_jobs.tsv')
    uniqtokens, nbefore, nafter = unique(alltokens)

    for term in uniqtokens:
        term_vector = []
        for ti in range(0, len(alltexts)):
            text = alltexts[ti]
            tfidf = alltexts.tf_idf (term, text)
            term_vector.append(tfidf)
        print term, term_vector
